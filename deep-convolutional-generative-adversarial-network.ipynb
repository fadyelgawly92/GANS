{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array, array_to_img \nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Lambda\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2DTranspose, Conv2D, add, concatenate\nfrom tensorflow.keras.layers import LeakyReLU, Activation, Reshape\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-08T21:14:42.338534Z","iopub.execute_input":"2022-07-08T21:14:42.338947Z","iopub.status.idle":"2022-07-08T21:14:49.374746Z","shell.execute_reply.started":"2022-07-08T21:14:42.338861Z","shell.execute_reply":"2022-07-08T21:14:49.373642Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"attributes = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv')\nbboxes = pd.read_csv('../input/celeba-dataset/list_bbox_celeba.csv')\npartition = pd.read_csv('../input/celeba-dataset/list_eval_partition.csv')\nlandmarks = pd.read_csv('../input/celeba-dataset/list_landmarks_align_celeba.csv')\nbase_directory = '../input/celeba-dataset/img_align_celeba/img_align_celeba'\n#base_directory = 'D:\\GAN\\GAN_Facedataset'","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:49.380311Z","iopub.execute_input":"2022-07-08T21:14:49.382998Z","iopub.status.idle":"2022-07-08T21:14:51.473816Z","shell.execute_reply.started":"2022-07-08T21:14:49.382959Z","shell.execute_reply":"2022-07-08T21:14:51.472723Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('../input/celeba-dataset/img_align_celeba/img_align_celeba')[:20]","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:51.478719Z","iopub.execute_input":"2022-07-08T21:14:51.481039Z","iopub.status.idle":"2022-07-08T21:14:54.737354Z","shell.execute_reply.started":"2022-07-08T21:14:51.481001Z","shell.execute_reply":"2022-07-08T21:14:54.736423Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimages = []\nlisted_images = os.listdir('../input/celeba-dataset/img_align_celeba/img_align_celeba')[:20]\nfor img_path in listed_images:\n    img_path = base_directory+'/'+img_path\n    images.append(mpimg.imread(img_path))\nimages = images[:20]\n\nplt.figure(figsize=(20,10))\ncolumns = 5\nfor i, image in enumerate(images):\n    plt.subplot(4, 5, i + 1)\n    plt.axis('off')\n    #fig.tight_layout() \n    plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:54.744665Z","iopub.execute_input":"2022-07-08T21:14:54.746941Z","iopub.status.idle":"2022-07-08T21:14:57.134884Z","shell.execute_reply.started":"2022-07-08T21:14:54.746903Z","shell.execute_reply":"2022-07-08T21:14:57.133923Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"landmarks_df = pd.read_csv('../input/celeba-dataset/list_landmarks_align_celeba.csv')\nlandmarks_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:57.136078Z","iopub.execute_input":"2022-07-08T21:14:57.136446Z","iopub.status.idle":"2022-07-08T21:14:57.619474Z","shell.execute_reply.started":"2022-07-08T21:14:57.136406Z","shell.execute_reply":"2022-07-08T21:14:57.618390Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"paths_to_images = '../input/celeba-dataset/img_align_celeba/img_align_celeba/000002.jpg'\n\n\n#current_landmarks = landmarks.query('image_id == \"{}\"'.format(paths_to_images.split('\\\\')[-1]))\n#print(\"Current landmark ; \",current_landmarks)\n\n\neye_x, eye_y, eye_w, eye_h = np.array(landmarks.iloc[:, 1:5])[1]\nnose_x,\tnose_y,\tleftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y = np.array(landmarks.iloc[:, 5:])[1]\n\nleft_eye = (eye_x, eye_y)\nright_eye = (eye_w, eye_h)\nnose = (nose_x + 10,nose_y)\nleft_mounth = (leftmouth_x, leftmouth_y)\nright_mounth = (rightmouth_x, rightmouth_y)\n\nexample_image = cv2.imread(paths_to_images)\noriginal_image = example_image.copy()\n\n\nexample_image = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n\nexample_image = cv2.line(example_image, left_eye, right_eye, (0, 255, 255),1)\nexample_image = cv2.line(example_image, left_eye, nose, (0, 255, 255), 1)\nexample_image = cv2.line(example_image, right_eye, nose, (0, 255, 255), 1)\nexample_image = cv2.line(example_image, nose, left_mounth,(0, 255, 255), 1)\nexample_image = cv2.line(example_image, nose, right_mounth, (0, 255, 255), 1)\n\nplt.figure(figsize = (10, 20))\nplt.subplot(1,2,1)\nplt.axis('off')\nplt.title('original image')\nplt.imshow(original_image)\nplt.subplot(1,2,2)\nplt.axis('off')\nplt.title('Image with landmarks')\nplt.imshow(example_image)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:57.620764Z","iopub.execute_input":"2022-07-08T21:14:57.624906Z","iopub.status.idle":"2022-07-08T21:14:58.068702Z","shell.execute_reply.started":"2022-07-08T21:14:57.624867Z","shell.execute_reply":"2022-07-08T21:14:58.067605Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"bboxes_df = pd.read_csv('../input/celeba-dataset/list_bbox_celeba.csv')\nbboxes_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.070440Z","iopub.execute_input":"2022-07-08T21:14:58.071128Z","iopub.status.idle":"2022-07-08T21:14:58.308647Z","shell.execute_reply.started":"2022-07-08T21:14:58.071089Z","shell.execute_reply":"2022-07-08T21:14:58.307683Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"current_bbox = bboxes.query('image_id == \"{}\"'.format(paths_to_images.split('/')[-1]))\nprint(current_bbox)\n\nx, y, w, h = np.array(current_bbox.iloc[:, 1:])[0]\n\nexample_image = cv2.rectangle(example_image, (x - w, y ), (w , h ), (0, 255, 255), 1)\n\nplt.figure(figsize = (10, 20))\nplt.subplot(1,2,1)\nplt.axis('off')\nplt.title('original image')\nplt.imshow(original_image)\nplt.subplot(1,2,2)\nplt.axis('off')\nplt.title('Image with bbox and landmarks')\nplt.imshow(example_image)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.313291Z","iopub.execute_input":"2022-07-08T21:14:58.315834Z","iopub.status.idle":"2022-07-08T21:14:58.716783Z","shell.execute_reply.started":"2022-07-08T21:14:58.315781Z","shell.execute_reply":"2022-07-08T21:14:58.715778Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"partition_df = pd.read_csv('../input/celeba-dataset/list_eval_partition.csv')\npartition_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.718297Z","iopub.execute_input":"2022-07-08T21:14:58.718906Z","iopub.status.idle":"2022-07-08T21:14:58.912501Z","shell.execute_reply.started":"2022-07-08T21:14:58.718866Z","shell.execute_reply":"2022-07-08T21:14:58.911479Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"partition_df['partition'].value_counts()\n# Have 3 partitions  (partition is just recomended parameter of dataset distribution)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.919389Z","iopub.execute_input":"2022-07-08T21:14:58.921679Z","iopub.status.idle":"2022-07-08T21:14:58.934600Z","shell.execute_reply.started":"2022-07-08T21:14:58.921635Z","shell.execute_reply":"2022-07-08T21:14:58.933519Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_images = partition.query('partition == 0')\nvalid_images = partition.query('partition == 1')\ntest_images = partition.query('partition == 2')","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.936202Z","iopub.execute_input":"2022-07-08T21:14:58.936952Z","iopub.status.idle":"2022-07-08T21:14:58.968568Z","shell.execute_reply.started":"2022-07-08T21:14:58.936917Z","shell.execute_reply":"2022-07-08T21:14:58.967654Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"attributes_df = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv')\nattributes_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:14:58.969969Z","iopub.execute_input":"2022-07-08T21:14:58.970693Z","iopub.status.idle":"2022-07-08T21:15:00.002889Z","shell.execute_reply.started":"2022-07-08T21:14:58.970659Z","shell.execute_reply":"2022-07-08T21:15:00.001846Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\ndiscriminator = keras.Sequential(\n    [\n        keras.Input(shape=(64, 64, 3)),\n        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Flatten(),\n        layers.Dropout(0.2),\n        layers.Dense(1, activation=\"sigmoid\"),\n    ],\n    name=\"discriminator\",\n)\ndiscriminator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:00.007250Z","iopub.execute_input":"2022-07-08T21:15:00.008152Z","iopub.status.idle":"2022-07-08T21:15:02.950904Z","shell.execute_reply.started":"2022-07-08T21:15:00.008109Z","shell.execute_reply":"2022-07-08T21:15:02.949947Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nlatent_dim = 100\n\ngenerator = keras.Sequential(\n    [\n        keras.Input(shape=(latent_dim,)),\n        layers.Dense(8 * 8 * 128),\n        layers.Reshape((8, 8, 128)),\n        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n        layers.LeakyReLU(alpha=0.2),\n        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n    ],\n    name=\"generator\",\n)\ngenerator.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:02.952293Z","iopub.execute_input":"2022-07-08T21:15:02.953293Z","iopub.status.idle":"2022-07-08T21:15:03.029279Z","shell.execute_reply.started":"2022-07-08T21:15:02.953241Z","shell.execute_reply":"2022-07-08T21:15:03.028111Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset = keras.preprocessing.image_dataset_from_directory(\n    \"../input/celeba-dataset\", label_mode=None, image_size=(64, 64), batch_size=32\n)\ndataset = dataset.map(lambda x: x / 255.0)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:15:03.030748Z","iopub.execute_input":"2022-07-08T21:15:03.031908Z","iopub.status.idle":"2022-07-08T21:17:36.444207Z","shell.execute_reply.started":"2022-07-08T21:15:03.031869Z","shell.execute_reply":"2022-07-08T21:17:36.443357Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class GAN(keras.Model):\n    def __init__(self, discriminator, generator, latent_dim):\n        super(GAN, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\n        super(GAN, self).compile()\n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n\n    @property\n    def metrics(self):\n        return [self.d_loss_metric, self.g_loss_metric]\n\n    def train_step(self, real_images):\n        # Sample random points in the latent space\n        batch_size = tf.shape(real_images)[0]\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Decode them to fake images\n        generated_images = self.generator(random_latent_vectors)\n\n        # Combine them with real images\n        combined_images = tf.concat([generated_images, real_images], axis=0)\n\n        # Assemble labels discriminating real from fake images\n        labels = tf.concat(\n            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n        )\n        # Add random noise to the labels - important trick!\n        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n\n        # Train the discriminator\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(combined_images)\n            d_loss = self.loss_fn(labels, predictions)\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n        self.d_optimizer.apply_gradients(\n            zip(grads, self.discriminator.trainable_weights)\n        )\n\n        # Sample random points in the latent space\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n\n        # Assemble labels that say \"all real images\"\n        misleading_labels = tf.zeros((batch_size, 1))\n\n        # Train the generator (note that we should *not* update the weights\n        # of the discriminator)!\n        with tf.GradientTape() as tape:\n            predictions = self.discriminator(self.generator(random_latent_vectors))\n            g_loss = self.loss_fn(misleading_labels, predictions)\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n\n        # Update metrics\n        self.d_loss_metric.update_state(d_loss)\n        self.g_loss_metric.update_state(g_loss)\n        return {\n            \"d_loss\": self.d_loss_metric.result(),\n            \"g_loss\": self.g_loss_metric.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:17:36.453308Z","iopub.execute_input":"2022-07-08T21:17:36.453906Z","iopub.status.idle":"2022-07-08T21:17:36.471817Z","shell.execute_reply.started":"2022-07-08T21:17:36.453869Z","shell.execute_reply":"2022-07-08T21:17:36.470721Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=3, latent_dim=128):\n        self.num_img = num_img\n        self.latent_dim = latent_dim\n\n    def on_epoch_end(self, epoch, logs=None):\n        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n        generated_images = self.model.generator(random_latent_vectors)\n        generated_images *= 255\n        generated_images.numpy()\n        for i in range(self.num_img):\n            img = keras.preprocessing.image.array_to_img(generated_images[i])\n            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n            plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:17:36.473698Z","iopub.execute_input":"2022-07-08T21:17:36.474311Z","iopub.status.idle":"2022-07-08T21:17:36.487226Z","shell.execute_reply.started":"2022-07-08T21:17:36.474254Z","shell.execute_reply":"2022-07-08T21:17:36.486232Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"epochs = 50  # In practice, use ~100 epochs\n\ngan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\ngan.compile(\n    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n    loss_fn=keras.losses.BinaryCrossentropy(),\n)\n\ngan.fit(\n    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T21:17:36.488890Z","iopub.execute_input":"2022-07-08T21:17:36.489594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display a single image using the epoch number\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimages = []\nfor img_path in glob.glob('output_samples/*.png'):\n    images.append(mpimg.imread(img_path))\n\nplt.figure(figsize=(20,10))\ncolumns = 20\nfor i, image in enumerate(images):\n    plt.subplot(len(images) / columns + 1, columns, i + 1)\n    plt.axis('off')\n    #fig.tight_layout() \n    plt.imshow(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}